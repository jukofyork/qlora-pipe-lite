# ==============================
# MODEL AND OUTPUT CONFIGURATION
# ==============================

model_dir = '/mnt/shared/models/DeepSeek-V3-0324-DRAFT-0.6B-UNTRAINED'
output_dir = '/mnt/shared/finetunes/finetuned'

# ===========================
# TRAINING TYPE CONFIGURATION
# ===========================

full_fine_tune = true

# =======================
# OPTIMIZER CONFIGURATION
# =======================

lr = 5e-5

# ======================
# TRAINING CONFIGURATION
# ======================

sequence_len = 32768

gradient_accumulation_steps = 10  # 10×6 = batch size 60, 10×6×32768 = ~2M tokens per step

# =====================
# DATASET CONFIGURATION
# =====================

[[datasets]]
dataset_path = '/mnt/shared/datasets/common-crawl-sample/*.json'
drop_tails = true

[[datasets]]
dataset_path = '/mnt/shared/datasets/the-stack-smol-xl/*.jsonl'
drop_tails = true

[[datasets]]
dataset_path = '/mnt/shared/datasets/rombodawg-Everything-Instruct/*.json'
drop_tails = true